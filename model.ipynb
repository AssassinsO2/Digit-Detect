{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CODE FOR TRAINING CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.api.utils import to_categorical\n",
    "from keras.api.models import Sequential, load_model\n",
    "from keras.api.layers import Dense, Dropout, Flatten, Conv2D, BatchNormalization, Input\n",
    "from keras.api.callbacks import LearningRateScheduler\n",
    "\n",
    "# LOAD THE DATA\n",
    "train = pd.read_csv(\"datasets\\\\train.csv\")\n",
    "test = pd.read_csv(\"datasets\\\\test.csv\")\n",
    "\n",
    "# PREPARE DATA FOR NEURAL NETWORK\n",
    "Y_train = train[\"label\"]\n",
    "X_train = train.drop(labels=[\"label\"], axis=1)\n",
    "X_train = X_train / 255.0\n",
    "X_test = test / 255.0\n",
    "X_train = X_train.values.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.values.reshape(-1, 28, 28, 1)\n",
    "Y_train = to_categorical(Y_train, num_classes=10)\n",
    "\n",
    "# PREVIEW IMAGES\n",
    "plt.figure(figsize=(15, 4.5))\n",
    "for i in range(30):\n",
    "    plt.subplot(3, 10, i + 1)\n",
    "    plt.imshow(X_train[i].reshape((28, 28)), cmap=plt.cm.binary)\n",
    "    plt.axis('off')\n",
    "plt.subplots_adjust(wspace=-0.1, hspace=-0.1)\n",
    "plt.show()\n",
    "\n",
    "# CREATE MORE IMAGES VIA DATA AUGMENTATION\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "# PREVIEW AUGMENTED IMAGES\n",
    "X_train3 = X_train[9,].reshape((1, 28, 28, 1))\n",
    "Y_train3 = Y_train[9,].reshape((1, 10))\n",
    "plt.figure(figsize=(15, 4.5))\n",
    "for i in range(30):\n",
    "    plt.subplot(3, 10, i + 1)\n",
    "    X_train2, Y_train2 = next(datagen.flow(X_train3, Y_train3))\n",
    "    plt.imshow(X_train2[0].reshape((28, 28)), cmap=plt.cm.binary)\n",
    "    plt.axis('off')\n",
    "    if i == 9: X_train3 = X_train[11,].reshape((1, 28, 28, 1))\n",
    "    if i == 19: X_train3 = X_train[18,].reshape((1, 28, 28, 1))\n",
    "plt.subplots_adjust(wspace=-0.1, hspace=-0.1)\n",
    "plt.show()\n",
    "\n",
    "# Check if models are already saved and load them, or train if not found\n",
    "nets = 5\n",
    "model = [0] * nets\n",
    "history = [0] * nets\n",
    "models_directory = \"trained_models\"\n",
    "os.makedirs(models_directory, exist_ok=True)\n",
    "\n",
    "for j in range(nets):\n",
    "    model_path = os.path.join(models_directory, f\"model_{j}.keras\") \n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"Loading model_{j} from {models_directory}...\")\n",
    "        model[j] = load_model(model_path)\n",
    "    else:\n",
    "        print(f\"Model {j} not found. Training the model...\")\n",
    "        model[j] = Sequential()\n",
    "        model[j].add(Input(shape=(28, 28, 1)))\n",
    "        model[j].add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "        model[j].add(BatchNormalization())\n",
    "        model[j].add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "        model[j].add(BatchNormalization())\n",
    "        model[j].add(Conv2D(32, kernel_size=5, strides=2, padding='same', activation='relu'))\n",
    "        model[j].add(BatchNormalization())\n",
    "        model[j].add(Dropout(0.4))\n",
    "\n",
    "        model[j].add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "        model[j].add(BatchNormalization())\n",
    "        model[j].add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "        model[j].add(BatchNormalization())\n",
    "        model[j].add(Conv2D(64, kernel_size=5, strides=2, padding='same', activation='relu'))\n",
    "        model[j].add(BatchNormalization())\n",
    "        model[j].add(Dropout(0.4))\n",
    "\n",
    "        model[j].add(Conv2D(128, kernel_size=4, activation='relu'))\n",
    "        model[j].add(BatchNormalization())\n",
    "        model[j].add(Flatten())\n",
    "        model[j].add(Dropout(0.4))\n",
    "        model[j].add(Dense(10, activation='softmax'))\n",
    "\n",
    "        # Compile and train the model\n",
    "        model[j].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "        X_train2, X_val2, Y_train2, Y_val2 = train_test_split(X_train, Y_train, test_size=0.1)\n",
    "\n",
    "        epo = 30\n",
    "        history[j] = model[j].fit(\n",
    "            datagen.flow(X_train2, Y_train2, batch_size=64),\n",
    "            epochs=epo,\n",
    "            steps_per_epoch=len(X_train2) // (epo*64),  # Ensure the number of steps is appropriate\n",
    "            validation_data=(X_val2, Y_val2),\n",
    "            callbacks=[LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        print(\"CNN {0:d}: Epochs={1:d}, Train accuracy={2:.5f}, Validation accuracy={3:.5f}\".format(\n",
    "        j + 1, epo, max(history[j].history['accuracy']), max(history[j].history['val_accuracy'])))\n",
    "        20012002\n",
    "        # Save the trained model\n",
    "        model[j].save(model_path)\n",
    "        print(f\"Model {j} saved as {model_path}.\")\n",
    "\n",
    "# ENSEMBLE PREDICTIONS\n",
    "results = np.zeros((X_test.shape[0], 10))\n",
    "for j in range(nets):\n",
    "    results = results + model[j].predict(X_test)\n",
    "results = np.argmax(results, axis=1)\n",
    "results = pd.Series(results, name=\"Label\")\n",
    "\n",
    "# PREVIEW PREDICTIONS\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i in range(30):\n",
    "    plt.subplot(4, 10, i + 1)\n",
    "    plt.imshow(X_test[i].reshape((28, 28)), cmap=plt.cm.binary)\n",
    "    plt.title(\"predict=%d\" % results[i], y=0.9)\n",
    "    plt.axis('off')\n",
    "plt.subplots_adjust(wspace=0.3, hspace=-0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CODE FOR TESTING CNN MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"\n",
    "    Load and preprocess the image for prediction.\n",
    "    - Convert the image to grayscale.\n",
    "    - Resize it to 28x28 pixels.\n",
    "    - Invert pixel values if necessary.\n",
    "    \"\"\"\n",
    "    # Load the image in grayscale\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Image at {image_path} not found or unable to load.\")\n",
    "    \n",
    "    # Resize to 28x28\n",
    "    img = cv2.resize(img, (28, 28))\n",
    "    \n",
    "    # Invert the pixel values\n",
    "    img = 255 - img \n",
    "\n",
    "    # Normalize pixel values to [0, 1].\n",
    "    img = img / 255.0\n",
    "\n",
    "    # Reshape to (1, 28, 28, 1) for the model input\n",
    "    img = img.reshape(1, 28, 28, 1)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def save_pixel_data(image, image_name, output_folder):\n",
    "    \"\"\"\n",
    "    Save the pixel values of the image in a CSV file.\n",
    "    - The data will be column-wise with column names like 'pixel0', 'pixel1', ..., 'pixel783'.\n",
    "    \"\"\"\n",
    "    # Flatten the image to 1D array (784 pixels)\n",
    "    pixel_data = image.flatten()\n",
    "    \n",
    "    # Create a DataFrame with pixel data\n",
    "    pixel_columns = [f\"pixel{i}\" for i in range(784)]\n",
    "    pixel_df = pd.DataFrame([pixel_data], columns=pixel_columns)\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    csv_filename = os.path.join(output_folder, f\"{image_name}_pixels.csv\")\n",
    "    pixel_df.to_csv(csv_filename, index=False)\n",
    "\n",
    "def predict_and_save_pixels(models, folder_path, image_count):\n",
    "    \"\"\"\n",
    "    Predict results, visualize each image, and save the pixel data in CSV files.\n",
    "    - `models`: List of trained models.\n",
    "    - `folder_path`: Folder containing images.\n",
    "    - `image_count`: Number of images to process.\n",
    "    \"\"\"\n",
    "    # Create a folder to store generated CSV files if it doesn't exist\n",
    "    output_folder = \"generated_csv_files\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for i in range(image_count):\n",
    "        image_name = f\"i{i}.png\"\n",
    "        image_path = os.path.join(folder_path, image_name)\n",
    "        \n",
    "        try:\n",
    "            # Preprocess the image\n",
    "            img = preprocess_image(image_path)\n",
    "            \n",
    "            # Initialize results array\n",
    "            results = np.zeros((1, 10))\n",
    "            \n",
    "            # Use each model in the ensemble to predict\n",
    "            for model in models:\n",
    "                # Ensure the model is compiled if necessary\n",
    "                if not model.compiled:\n",
    "                    model.compile()\n",
    "                \n",
    "                results += model.predict(img)\n",
    "\n",
    "            \n",
    "            # Normalize probabilities\n",
    "            probabilities = results / len(models)\n",
    "            probabilities = probabilities.flatten()\n",
    "            \n",
    "            # Get the predicted label\n",
    "            predicted_label = np.argmax(probabilities)\n",
    "            \n",
    "            # Display the image with its probabilities\n",
    "            plt.figure(figsize=(15, 6))\n",
    "            plt.subplot(4, 10, 1)\n",
    "            plt.imshow(img.reshape(28, 28), cmap=plt.cm.binary)\n",
    "            plt.axis('off')\n",
    "            prob_str = \"\\n\".join([f\"Probability of {i}: {p:.10f}\" for i, p in enumerate(probabilities)])\n",
    "            plt.title(f\"{image_name}: Predicted: {predicted_label}\\nProbabilities:\\n{prob_str}\")\n",
    "            plt.show()\n",
    "            \n",
    "            # Save the pixel data to a CSV file\n",
    "            save_pixel_data(img, image_name, output_folder)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_name}: {e}\")\n",
    "\n",
    "folder_path = \"Predict Image\"  # Folder containing images i0.png to i25.png\n",
    "image_count = 25  # Total number of images to process (i0 to i25)\n",
    "\n",
    "try:\n",
    "    predict_and_save_pixels(model, folder_path, image_count)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
